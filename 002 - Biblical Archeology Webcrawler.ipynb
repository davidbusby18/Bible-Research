{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Web Crawler\n",
    "\n",
    "I am going to create a web crawler that pulls articles related to Biblical archeology and a list of nations found in the Bible. I want to be considerate of those hosting these articles, so I am going to pause the webcrawler after each iteration. I will then save all of the articles to a permanent dataset for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from googlesearch import search \n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to writing this code, I visited this Wikipedia page to find a list of all nations mentioned in the Bible: https://en.wikipedia.org/wiki/List_of_nations_mentioned_in_the_Bible. I copied these names into an ODS file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Bible Research/data/List of nations in Bible.ods\"\n",
    "\n",
    "# load a sheet based on its index (1 based)\n",
    "sheet_idx = 1\n",
    "nations = read_ods(path, sheet_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 110 nations mentioned in the Bible. We will look for any websites about archeological finds related to those nations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Adramyttium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Almon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Antioch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Aphek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Nation\n",
       "0  Adramyttium\n",
       "1           Ai\n",
       "2        Almon\n",
       "3      Antioch\n",
       "4        Aphek"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to I write the webcrawler. The first thing I do is create an empty list called *all_nations*. Then, within a FOR loop, I then ask the program to print the name of each nation as it is being queried. This is not necessary, but it allows me to keep track of progress.\n",
    "\n",
    "I then create a web query that requires the key words \"archeology\" OR \"aftifact,\" \"Bible\" and the name of the nation that is being queried. This site was helpful: https://www.geeksforgeeks.org/performing-google-search-using-python-code/. I decided to query the first ten articles related to each nation with the requred key words, but I also told the query to stop at result 25. I did this so that the search did not go too deep, i.e. page 4 searches. I also told the program to pause for 10 seconds between each website it queried. I also build in a pause of 3 seconds. Some of the features of the function I used did not work as I expected. I will need to dig into this at a later date. After each quary, I append the web address to the list *all_nations*. Finally, I make the program wait 30 seconds between each nation in order to be respectful of Google. This site was helpful: https://www.pythoncentral.io/pythons-time-sleep-pause-wait-sleep-stop-your-code/. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adramyttium\n",
      "Ai\n",
      "Almon\n",
      "Antioch\n",
      "Aphek\n",
      "Assos\n",
      "Attalia\n",
      "Awen\n",
      "Baal_shalisha\n",
      "Babylon\n",
      "Berea\n",
      "Arbel\n",
      "Beth_anath\n",
      "Beth_tappuah\n",
      "Bozrah\n",
      "Bubastis\n",
      "Cauda\n",
      "Cenchrea\n",
      "Chezib\n",
      "Cuthah\n",
      "Dedan\n",
      "Ecbatana\n",
      "Elim\n",
      "En_gannim\n",
      "Erech\n",
      "Eshtemoa\n",
      "Etam\n",
      "Gath\n",
      "Gath_hepher\n",
      "Gerar\n",
      "Gerasa\n",
      "Gibeah\n",
      "Giloh\n",
      "Gozan\n",
      "Haggoyim\n",
      "Hamath\n",
      "Hammath\n",
      "Hapharaim\n",
      "Harosheth\n",
      "Hazezon_tamar\n",
      "Hukok\n",
      "Ible_am\n",
      "Iconium\n",
      "Iron\n",
      "Jaffo\n",
      "Jezreel\n",
      "Kadesh\n",
      "Kadesh_barnea\n",
      "Kedesh_naphtali\n",
      "Kir\n",
      "Kiriath_Jearim\n",
      "Kitron\n",
      "Laish\n",
      "Leshem\n",
      "Lod\n",
      "Lystra\n",
      "Medeba\n",
      "Mitylene\n",
      "Myra\n",
      "Neapolis\n",
      "Nephtoah\n",
      "Nicopolis\n",
      "No\n",
      "No_amon\n",
      "Noph\n",
      "Noph\n",
      "On\n",
      "Ono\n",
      "Ophir\n",
      "Ophrah\n",
      "Pelusium\n",
      "Pergamum\n",
      "Philadelphia\n",
      "Pi_beseth\n",
      "Pirathon\n",
      "Ptolemais\n",
      "Puteoli\n",
      "QiryatArba\n",
      "Rabbah\n",
      "Rabbah\n",
      "Rakkath\n",
      "Ramah\n",
      "Rhegium\n",
      "Sarepta\n",
      "Seba\n",
      "Sheba\n",
      "Shechem\n",
      "Shiloah\n",
      "Shomron\n",
      "Shunem\n",
      "Sin\n",
      "Smyrna\n",
      "Socoh\n",
      "Succoth\n",
      "Susa\n",
      "Syene\n",
      "Tadmor\n",
      "Tahpanhes\n",
      "Thebes\n",
      "Thessalonica\n",
      "Thyatira\n",
      "Timnah\n",
      "Timnath_heres\n",
      "Tirzah\n",
      "Ur\n",
      "Zaphon\n",
      "Zephathah\n",
      "Ziddim\n",
      "Zoan\n",
      "Zorah\n"
     ]
    }
   ],
   "source": [
    "all_nations = []\n",
    "for index, row in nations.iterrows():\n",
    "    \n",
    "    print(row[0])\n",
    "\n",
    "    query = \"archeology OR artifact + Bible +\" + row[0]\n",
    "    \n",
    "    for j in search(query, num=10, stop=25, pause=10):\n",
    "        time.sleep(3)\n",
    "        \n",
    "        all_nations.append(j)\n",
    "\n",
    "    time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will unduplicate this list of websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nations = pd.Series(all_nations)\n",
    "nations2 = pd.Series(all_nations.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    https://biblearchaeologyreport.com/2019/04/12/...\n",
       "1            https://en.wikipedia.org/wiki/Ai_(Canaan)\n",
       "2    https://en.wikipedia.org/wiki/Ai_(Canaan)#Bibl...\n",
       "3    https://en.wikipedia.org/wiki/Ai_(Canaan)#Poss...\n",
       "4    https://en.wikipedia.org/wiki/Ai_(Canaan)#Et-Tell\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nations2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I need to output this list to a CSV file that can be label as relevant or irrelevant. I will then use this labeled list of websites to create a predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nations2.to_pickle(\"C:/Bible Research/data/archeology websites about nations.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nations2.to_csv(r'C:/Users/david/OneDrive/Desktop/Bible Research/00 Python Output/Places/all places.aacsv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
